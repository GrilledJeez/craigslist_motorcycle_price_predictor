{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import get to call a get request on the site\n",
    "import requests\n",
    "\n",
    "#import to manipulate arrays with numpy\n",
    "import numpy as np\n",
    "\n",
    "#import to create, clean, and parse data frames with pandas\n",
    "import pandas as pd\n",
    "\n",
    "#import to enable datascraping\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#import to set up 'sleep' to wait between page loads\n",
    "import time\n",
    "\n",
    "# import Mongo so our webscraper dumps its scraped data without losing it\n",
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "\n",
    "#import to make that html readable\n",
    "import pprint\n",
    "\n",
    "#import regular expressions operations\n",
    "import re\n",
    "\n",
    "#import to get the universe in balance\n",
    "import random\n",
    "\n",
    "#import so we can do some heavy stats work\n",
    "import scipy as sp\n",
    "from scipy.stats import binom\n",
    "import scipy.stats as stats\n",
    "\n",
    "#import to access certain plotting features\n",
    "import seaborn as sns\n",
    "\n",
    "#import because we need its program functions\n",
    "import math\n",
    "\n",
    "#import because we need to plot and make it pretty\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will collect the links for all cities on craigslist. We will have to sparse through\n",
    "# these and cut out the non-US cities.\n",
    "def city_link_collector():\n",
    "    # this is the craigslist page with every city\n",
    "    main_page = requests.get('https://www.craigslist.org/about/sites')\n",
    "    soup = BeautifulSoup(main_page.text, 'html.parser')\n",
    "    \n",
    "    all_list = []\n",
    "    uscity_list = []\n",
    "    city_list = []\n",
    "    \n",
    "    for i in range(4):\n",
    "        for box in soup.find_all('div', class_='box box_{}'.format(i+1)):\n",
    "            all_list.append(box.find_all('a'))\n",
    "    for _ in all_list[:20:7]:\n",
    "        for __ in _:\n",
    "            uscity_list.append(__)\n",
    "    for ___ in all_list[20][0:94]:\n",
    "        uscity_list.append(___)\n",
    "    \n",
    "    for idx, city in enumerate(uscity_list):\n",
    "        city_list.append(str(uscity_list[idx]).split('''\"''')[1])\n",
    "    \n",
    "    '''These listings are all a subset of Miami and break the scraper if entered in this format'''\n",
    "    city_list.remove('http://miami.craigslist.org/brw/')\n",
    "    city_list.remove('http://miami.craigslist.org/mdc/')\n",
    "    city_list.remove('http://miami.craigslist.org/pbc/')\n",
    "    '''Here is the Miami list to capture the dropped entries and will not break the scraper'''\n",
    "    city_list.append('http://miami.craigslist.org/')\n",
    "    return city_list\n",
    "    #                     #posting date\n",
    "    #                     #grab the datetime element 0 for date and 1 for time\n",
    "    #                     post_datetime = box.find('time', class_= 'result-date')['datetime']\n",
    "    #                     post_timing.append(post_datetime)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_list = city_link_collector()\n",
    "len(city_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def craigslist_motorcycle_scraper(city_list):\n",
    "    client = MongoClient('localhost', 27017)\n",
    "    db = client['craigslist_motorcycles']\n",
    "    post_html = db['motorcycle_posts']\n",
    "    for city in city_list: \n",
    "\n",
    "        #get the first page of the Austin motorcycle prices\n",
    "        city_response = requests.get('{}search/mca?s=0&bundleDuplicates=1'.format(city))\n",
    "        #parse through it and make it readable\n",
    "        html_soup = BeautifulSoup(city_response.text, 'html.parser')\n",
    "        #find the total number of posts to find the limit for each page\n",
    "        results_num = html_soup.find('div', class_= 'search-legend')\n",
    "        #pulled the total count of posts as the upper bound of the pages array\n",
    "        results_total = int(results_num.find('span', class_='totalcount').text) \n",
    "        #each page has 119 posts so each new page is defined as follows: s=120, s=240, s=360, and so on. So we need to step in size 120 in the np.arange function\n",
    "        pages = np.arange(0, results_total+1, 120)\n",
    "        print(\"{} Posts = {}\".format(city, results_total))\n",
    "        print(\"{} Pages = {}\".format(city.title(), len(pages)))\n",
    "\n",
    "        iterations = 0\n",
    "\n",
    "        for page in pages:         \n",
    "            \n",
    "            #get request      \n",
    "            post_response = requests.get(\"{}search/mca?\".format(city) \n",
    "                           + \"s=\" #the parameter for defining the page number \n",
    "                           + str(page) #the page number in the pages array from earlier\n",
    "                           + \"&bundleDuplicates=1\")\n",
    "\n",
    "            time.sleep(random.randint(2,3))\n",
    "\n",
    "            #throw warning for status codes that are not 200\n",
    "            if post_response.status_code != 200:\n",
    "                warn('Request: {}; Status code: {}'.format(requests, post_response.status_code))\n",
    "\n",
    "            #define the html text\n",
    "            post_soup = BeautifulSoup(post_response.text, 'html.parser')\n",
    "\n",
    "            count = 0\n",
    "            for post in post_soup.find_all('a', class_ = 'result-title hdrlnk'):\n",
    "                link = post['href']\n",
    "                count += 1\n",
    "                \n",
    "#               checks to see if post html is loaded in our database and scrapes html if not\n",
    "                if not (post_html.find_one({'_id': link}, {'html': requests.get(link).text})):\n",
    "#                     print(str(link))\n",
    "                    sub_post = requests.get(link)\n",
    "                    post_html.insert_one({'_id': link, 'html': sub_post.text})\n",
    "                    if sub_post.status_code != 200:\n",
    "                        warn('Request: {}; Status code: {}'.format(requests, post_response.status_code))\n",
    "                    time.sleep(random.randint(2,3)) #sleep timer to avoid being banned      \n",
    "                else:\n",
    "#                     print('Passing ' + str(link))\n",
    "                    pass\n",
    "                         \n",
    "                if count == results_total:\n",
    "                    break\n",
    "\n",
    "            iterations += 1\n",
    "            print(\"{} Page \".format(city.title()) + str(iterations) + \" of {} pages\".format(len(pages)) + \" scraped successfully!\")\n",
    "\n",
    "            \n",
    "\n",
    "        print(\"\\n\")\n",
    "        print(\"{} complete!\".format(city.title()))\n",
    "        print('~' + str(len(pages)*120) + \" rows collected.\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "db = client['craigslist_motorcycles']\n",
    "post_html = db['motorcycle_posts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://minneapolis.craigslist.org/ Posts = 1317\n",
      "Https://Minneapolis.Craigslist.Org/ Pages = 11\n",
      "Https://Minneapolis.Craigslist.Org/ Page 1 of 11 pages scraped successfully!\n",
      "Https://Minneapolis.Craigslist.Org/ Page 2 of 11 pages scraped successfully!\n",
      "Https://Minneapolis.Craigslist.Org/ Page 3 of 11 pages scraped successfully!\n",
      "Https://Minneapolis.Craigslist.Org/ Page 4 of 11 pages scraped successfully!\n",
      "Https://Minneapolis.Craigslist.Org/ Page 5 of 11 pages scraped successfully!\n",
      "Https://Minneapolis.Craigslist.Org/ Page 6 of 11 pages scraped successfully!\n",
      "Https://Minneapolis.Craigslist.Org/ Page 7 of 11 pages scraped successfully!\n",
      "Https://Minneapolis.Craigslist.Org/ Page 8 of 11 pages scraped successfully!\n",
      "Https://Minneapolis.Craigslist.Org/ Page 9 of 11 pages scraped successfully!\n",
      "Https://Minneapolis.Craigslist.Org/ Page 10 of 11 pages scraped successfully!\n",
      "Https://Minneapolis.Craigslist.Org/ Page 11 of 11 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Minneapolis.Craigslist.Org/ complete!\n",
      "~1320 rows collected.\n",
      "\n",
      "\n",
      "https://rmn.craigslist.org/ Posts = 99\n",
      "Https://Rmn.Craigslist.Org/ Pages = 1\n",
      "Https://Rmn.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Rmn.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://marshall.craigslist.org/ Posts = 26\n",
      "Https://Marshall.Craigslist.Org/ Pages = 1\n",
      "Https://Marshall.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Marshall.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://stcloud.craigslist.org/ Posts = 128\n",
      "Https://Stcloud.Craigslist.Org/ Pages = 2\n",
      "Https://Stcloud.Craigslist.Org/ Page 1 of 2 pages scraped successfully!\n",
      "Https://Stcloud.Craigslist.Org/ Page 2 of 2 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Stcloud.Craigslist.Org/ complete!\n",
      "~240 rows collected.\n",
      "\n",
      "\n",
      "https://gulfport.craigslist.org/ Posts = 22\n",
      "Https://Gulfport.Craigslist.Org/ Pages = 1\n",
      "Https://Gulfport.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Gulfport.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://hattiesburg.craigslist.org/ Posts = 18\n",
      "Https://Hattiesburg.Craigslist.Org/ Pages = 1\n",
      "Https://Hattiesburg.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Hattiesburg.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://jackson.craigslist.org/ Posts = 29\n",
      "Https://Jackson.Craigslist.Org/ Pages = 1\n",
      "Https://Jackson.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Jackson.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://meridian.craigslist.org/ Posts = 2\n",
      "Https://Meridian.Craigslist.Org/ Pages = 1\n",
      "Https://Meridian.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Meridian.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://northmiss.craigslist.org/ Posts = 48\n",
      "Https://Northmiss.Craigslist.Org/ Pages = 1\n",
      "Https://Northmiss.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Northmiss.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://natchez.craigslist.org/ Posts = 3\n",
      "Https://Natchez.Craigslist.Org/ Pages = 1\n",
      "Https://Natchez.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Natchez.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://columbiamo.craigslist.org/ Posts = 47\n",
      "Https://Columbiamo.Craigslist.Org/ Pages = 1\n",
      "Https://Columbiamo.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Columbiamo.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://joplin.craigslist.org/ Posts = 35\n",
      "Https://Joplin.Craigslist.Org/ Pages = 1\n",
      "Https://Joplin.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Joplin.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://kansascity.craigslist.org/ Posts = 605\n",
      "Https://Kansascity.Craigslist.Org/ Pages = 6\n",
      "Https://Kansascity.Craigslist.Org/ Page 1 of 6 pages scraped successfully!\n",
      "Https://Kansascity.Craigslist.Org/ Page 2 of 6 pages scraped successfully!\n",
      "Https://Kansascity.Craigslist.Org/ Page 3 of 6 pages scraped successfully!\n",
      "Https://Kansascity.Craigslist.Org/ Page 4 of 6 pages scraped successfully!\n",
      "Https://Kansascity.Craigslist.Org/ Page 5 of 6 pages scraped successfully!\n",
      "Https://Kansascity.Craigslist.Org/ Page 6 of 6 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Kansascity.Craigslist.Org/ complete!\n",
      "~720 rows collected.\n",
      "\n",
      "\n",
      "https://kirksville.craigslist.org/ Posts = 4\n",
      "Https://Kirksville.Craigslist.Org/ Pages = 1\n",
      "Https://Kirksville.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Kirksville.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://loz.craigslist.org/ Posts = 20\n",
      "Https://Loz.Craigslist.Org/ Pages = 1\n",
      "Https://Loz.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Loz.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://semo.craigslist.org/ Posts = 44\n",
      "Https://Semo.Craigslist.Org/ Pages = 1\n",
      "Https://Semo.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Semo.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://springfield.craigslist.org/ Posts = 168\n",
      "Https://Springfield.Craigslist.Org/ Pages = 2\n",
      "Https://Springfield.Craigslist.Org/ Page 1 of 2 pages scraped successfully!\n",
      "Https://Springfield.Craigslist.Org/ Page 2 of 2 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Springfield.Craigslist.Org/ complete!\n",
      "~240 rows collected.\n",
      "\n",
      "\n",
      "https://stjoseph.craigslist.org/ Posts = 13\n",
      "Https://Stjoseph.Craigslist.Org/ Pages = 1\n",
      "Https://Stjoseph.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Stjoseph.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://stlouis.craigslist.org/ Posts = 411\n",
      "Https://Stlouis.Craigslist.Org/ Pages = 4\n",
      "Https://Stlouis.Craigslist.Org/ Page 1 of 4 pages scraped successfully!\n",
      "Https://Stlouis.Craigslist.Org/ Page 2 of 4 pages scraped successfully!\n",
      "Https://Stlouis.Craigslist.Org/ Page 3 of 4 pages scraped successfully!\n",
      "Https://Stlouis.Craigslist.Org/ Page 4 of 4 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Stlouis.Craigslist.Org/ complete!\n",
      "~480 rows collected.\n",
      "\n",
      "\n",
      "https://billings.craigslist.org/ Posts = 84\n",
      "Https://Billings.Craigslist.Org/ Pages = 1\n",
      "Https://Billings.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Billings.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://bozeman.craigslist.org/ Posts = 83\n",
      "Https://Bozeman.Craigslist.Org/ Pages = 1\n",
      "Https://Bozeman.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Bozeman.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://butte.craigslist.org/ Posts = 30\n",
      "Https://Butte.Craigslist.Org/ Pages = 1\n",
      "Https://Butte.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Butte.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://greatfalls.craigslist.org/ Posts = 49\n",
      "Https://Greatfalls.Craigslist.Org/ Pages = 1\n",
      "Https://Greatfalls.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Greatfalls.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://helena.craigslist.org/ Posts = 54\n",
      "Https://Helena.Craigslist.Org/ Pages = 1\n",
      "Https://Helena.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Helena.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://kalispell.craigslist.org/ Posts = 68\n",
      "Https://Kalispell.Craigslist.Org/ Pages = 1\n",
      "Https://Kalispell.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Kalispell.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://missoula.craigslist.org/ Posts = 127\n",
      "Https://Missoula.Craigslist.Org/ Pages = 2\n",
      "Https://Missoula.Craigslist.Org/ Page 1 of 2 pages scraped successfully!\n",
      "Https://Missoula.Craigslist.Org/ Page 2 of 2 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Missoula.Craigslist.Org/ complete!\n",
      "~240 rows collected.\n",
      "\n",
      "\n",
      "https://montana.craigslist.org/ Posts = 6\n",
      "Https://Montana.Craigslist.Org/ Pages = 1\n",
      "Https://Montana.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Montana.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://grandisland.craigslist.org/ Posts = 19\n",
      "Https://Grandisland.Craigslist.Org/ Pages = 1\n",
      "Https://Grandisland.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Grandisland.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://lincoln.craigslist.org/ Posts = 80\n",
      "Https://Lincoln.Craigslist.Org/ Pages = 1\n",
      "Https://Lincoln.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Lincoln.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://northplatte.craigslist.org/ Posts = 20\n",
      "Https://Northplatte.Craigslist.Org/ Pages = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Https://Northplatte.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Northplatte.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://omaha.craigslist.org/ Posts = 287\n",
      "Https://Omaha.Craigslist.Org/ Pages = 3\n",
      "Https://Omaha.Craigslist.Org/ Page 1 of 3 pages scraped successfully!\n",
      "Https://Omaha.Craigslist.Org/ Page 2 of 3 pages scraped successfully!\n",
      "Https://Omaha.Craigslist.Org/ Page 3 of 3 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Omaha.Craigslist.Org/ complete!\n",
      "~360 rows collected.\n",
      "\n",
      "\n",
      "https://scottsbluff.craigslist.org/ Posts = 20\n",
      "Https://Scottsbluff.Craigslist.Org/ Pages = 1\n",
      "Https://Scottsbluff.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Scottsbluff.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://elko.craigslist.org/ Posts = 2\n",
      "Https://Elko.Craigslist.Org/ Pages = 1\n",
      "Https://Elko.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Elko.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://lasvegas.craigslist.org/ Posts = 517\n",
      "Https://Lasvegas.Craigslist.Org/ Pages = 5\n",
      "Https://Lasvegas.Craigslist.Org/ Page 1 of 5 pages scraped successfully!\n",
      "Https://Lasvegas.Craigslist.Org/ Page 2 of 5 pages scraped successfully!\n",
      "Https://Lasvegas.Craigslist.Org/ Page 3 of 5 pages scraped successfully!\n",
      "Https://Lasvegas.Craigslist.Org/ Page 4 of 5 pages scraped successfully!\n",
      "Https://Lasvegas.Craigslist.Org/ Page 5 of 5 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Lasvegas.Craigslist.Org/ complete!\n",
      "~600 rows collected.\n",
      "\n",
      "\n",
      "https://reno.craigslist.org/ Posts = 338\n",
      "Https://Reno.Craigslist.Org/ Pages = 3\n",
      "Https://Reno.Craigslist.Org/ Page 1 of 3 pages scraped successfully!\n",
      "Https://Reno.Craigslist.Org/ Page 2 of 3 pages scraped successfully!\n",
      "Https://Reno.Craigslist.Org/ Page 3 of 3 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Reno.Craigslist.Org/ complete!\n",
      "~360 rows collected.\n",
      "\n",
      "\n",
      "https://nh.craigslist.org/ Posts = 926\n",
      "Https://Nh.Craigslist.Org/ Pages = 8\n",
      "Https://Nh.Craigslist.Org/ Page 1 of 8 pages scraped successfully!\n",
      "Https://Nh.Craigslist.Org/ Page 2 of 8 pages scraped successfully!\n",
      "Https://Nh.Craigslist.Org/ Page 3 of 8 pages scraped successfully!\n",
      "Https://Nh.Craigslist.Org/ Page 4 of 8 pages scraped successfully!\n",
      "Https://Nh.Craigslist.Org/ Page 5 of 8 pages scraped successfully!\n",
      "Https://Nh.Craigslist.Org/ Page 6 of 8 pages scraped successfully!\n",
      "Https://Nh.Craigslist.Org/ Page 7 of 8 pages scraped successfully!\n",
      "Https://Nh.Craigslist.Org/ Page 8 of 8 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Nh.Craigslist.Org/ complete!\n",
      "~960 rows collected.\n",
      "\n",
      "\n",
      "https://cnj.craigslist.org/ Posts = 199\n",
      "Https://Cnj.Craigslist.Org/ Pages = 2\n",
      "Https://Cnj.Craigslist.Org/ Page 1 of 2 pages scraped successfully!\n",
      "Https://Cnj.Craigslist.Org/ Page 2 of 2 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Cnj.Craigslist.Org/ complete!\n",
      "~240 rows collected.\n",
      "\n",
      "\n",
      "https://jerseyshore.craigslist.org/ Posts = 84\n",
      "Https://Jerseyshore.Craigslist.Org/ Pages = 1\n",
      "Https://Jerseyshore.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Jerseyshore.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://newjersey.craigslist.org/ Posts = 268\n",
      "Https://Newjersey.Craigslist.Org/ Pages = 3\n",
      "Https://Newjersey.Craigslist.Org/ Page 1 of 3 pages scraped successfully!\n",
      "Https://Newjersey.Craigslist.Org/ Page 2 of 3 pages scraped successfully!\n",
      "Https://Newjersey.Craigslist.Org/ Page 3 of 3 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Newjersey.Craigslist.Org/ complete!\n",
      "~360 rows collected.\n",
      "\n",
      "\n",
      "https://southjersey.craigslist.org/ Posts = 127\n",
      "Https://Southjersey.Craigslist.Org/ Pages = 2\n",
      "Https://Southjersey.Craigslist.Org/ Page 1 of 2 pages scraped successfully!\n",
      "Https://Southjersey.Craigslist.Org/ Page 2 of 2 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Southjersey.Craigslist.Org/ complete!\n",
      "~240 rows collected.\n",
      "\n",
      "\n",
      "https://albuquerque.craigslist.org/ Posts = 243\n",
      "Https://Albuquerque.Craigslist.Org/ Pages = 3\n",
      "Https://Albuquerque.Craigslist.Org/ Page 1 of 3 pages scraped successfully!\n",
      "Https://Albuquerque.Craigslist.Org/ Page 2 of 3 pages scraped successfully!\n",
      "Https://Albuquerque.Craigslist.Org/ Page 3 of 3 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Albuquerque.Craigslist.Org/ complete!\n",
      "~360 rows collected.\n",
      "\n",
      "\n",
      "https://clovis.craigslist.org/ Posts = 2\n",
      "Https://Clovis.Craigslist.Org/ Pages = 1\n",
      "Https://Clovis.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Clovis.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://farmington.craigslist.org/ Posts = 19\n",
      "Https://Farmington.Craigslist.Org/ Pages = 1\n",
      "Https://Farmington.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Farmington.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://lascruces.craigslist.org/ Posts = 41\n",
      "Https://Lascruces.Craigslist.Org/ Pages = 1\n",
      "Https://Lascruces.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Lascruces.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://roswell.craigslist.org/ Posts = 9\n",
      "Https://Roswell.Craigslist.Org/ Pages = 1\n",
      "Https://Roswell.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Roswell.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://santafe.craigslist.org/ Posts = 63\n",
      "Https://Santafe.Craigslist.Org/ Pages = 1\n",
      "Https://Santafe.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Santafe.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://albany.craigslist.org/ Posts = 318\n",
      "Https://Albany.Craigslist.Org/ Pages = 3\n",
      "Https://Albany.Craigslist.Org/ Page 1 of 3 pages scraped successfully!\n",
      "Https://Albany.Craigslist.Org/ Page 2 of 3 pages scraped successfully!\n",
      "Https://Albany.Craigslist.Org/ Page 3 of 3 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Albany.Craigslist.Org/ complete!\n",
      "~360 rows collected.\n",
      "\n",
      "\n",
      "https://binghamton.craigslist.org/ Posts = 66\n",
      "Https://Binghamton.Craigslist.Org/ Pages = 1\n",
      "Https://Binghamton.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Binghamton.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://buffalo.craigslist.org/ Posts = 155\n",
      "Https://Buffalo.Craigslist.Org/ Pages = 2\n",
      "Https://Buffalo.Craigslist.Org/ Page 1 of 2 pages scraped successfully!\n",
      "Https://Buffalo.Craigslist.Org/ Page 2 of 2 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Buffalo.Craigslist.Org/ complete!\n",
      "~240 rows collected.\n",
      "\n",
      "\n",
      "https://catskills.craigslist.org/ Posts = 19\n",
      "Https://Catskills.Craigslist.Org/ Pages = 1\n",
      "Https://Catskills.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Catskills.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://chautauqua.craigslist.org/ Posts = 23\n",
      "Https://Chautauqua.Craigslist.Org/ Pages = 1\n",
      "Https://Chautauqua.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Chautauqua.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://elmira.craigslist.org/ Posts = 28\n",
      "Https://Elmira.Craigslist.Org/ Pages = 1\n",
      "Https://Elmira.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Elmira.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://fingerlakes.craigslist.org/ Posts = 27\n",
      "Https://Fingerlakes.Craigslist.Org/ Pages = 1\n",
      "Https://Fingerlakes.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Fingerlakes.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://glensfalls.craigslist.org/ Posts = 44\n",
      "Https://Glensfalls.Craigslist.Org/ Pages = 1\n",
      "Https://Glensfalls.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Glensfalls.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://hudsonvalley.craigslist.org/ Posts = 273\n",
      "Https://Hudsonvalley.Craigslist.Org/ Pages = 3\n",
      "Https://Hudsonvalley.Craigslist.Org/ Page 1 of 3 pages scraped successfully!\n",
      "Https://Hudsonvalley.Craigslist.Org/ Page 2 of 3 pages scraped successfully!\n",
      "Https://Hudsonvalley.Craigslist.Org/ Page 3 of 3 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Hudsonvalley.Craigslist.Org/ complete!\n",
      "~360 rows collected.\n",
      "\n",
      "\n",
      "https://ithaca.craigslist.org/ Posts = 27\n",
      "Https://Ithaca.Craigslist.Org/ Pages = 1\n",
      "Https://Ithaca.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Ithaca.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://longisland.craigslist.org/ Posts = 262\n",
      "Https://Longisland.Craigslist.Org/ Pages = 3\n",
      "Https://Longisland.Craigslist.Org/ Page 1 of 3 pages scraped successfully!\n",
      "Https://Longisland.Craigslist.Org/ Page 2 of 3 pages scraped successfully!\n",
      "Https://Longisland.Craigslist.Org/ Page 3 of 3 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Longisland.Craigslist.Org/ complete!\n",
      "~360 rows collected.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://newyork.craigslist.org/ Posts = 670\n",
      "Https://Newyork.Craigslist.Org/ Pages = 6\n",
      "Https://Newyork.Craigslist.Org/ Page 1 of 6 pages scraped successfully!\n",
      "Https://Newyork.Craigslist.Org/ Page 2 of 6 pages scraped successfully!\n",
      "Https://Newyork.Craigslist.Org/ Page 3 of 6 pages scraped successfully!\n",
      "Https://Newyork.Craigslist.Org/ Page 4 of 6 pages scraped successfully!\n",
      "Https://Newyork.Craigslist.Org/ Page 5 of 6 pages scraped successfully!\n",
      "Https://Newyork.Craigslist.Org/ Page 6 of 6 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Newyork.Craigslist.Org/ complete!\n",
      "~720 rows collected.\n",
      "\n",
      "\n",
      "https://oneonta.craigslist.org/ Posts = 10\n",
      "Https://Oneonta.Craigslist.Org/ Pages = 1\n",
      "Https://Oneonta.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Oneonta.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://plattsburgh.craigslist.org/ Posts = 55\n",
      "Https://Plattsburgh.Craigslist.Org/ Pages = 1\n",
      "Https://Plattsburgh.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Plattsburgh.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://potsdam.craigslist.org/ Posts = 86\n",
      "Https://Potsdam.Craigslist.Org/ Pages = 1\n",
      "Https://Potsdam.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Potsdam.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://rochester.craigslist.org/ Posts = 149\n",
      "Https://Rochester.Craigslist.Org/ Pages = 2\n",
      "Https://Rochester.Craigslist.Org/ Page 1 of 2 pages scraped successfully!\n",
      "Https://Rochester.Craigslist.Org/ Page 2 of 2 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Rochester.Craigslist.Org/ complete!\n",
      "~240 rows collected.\n",
      "\n",
      "\n",
      "https://syracuse.craigslist.org/ Posts = 238\n",
      "Https://Syracuse.Craigslist.Org/ Pages = 2\n",
      "Https://Syracuse.Craigslist.Org/ Page 1 of 2 pages scraped successfully!\n",
      "Https://Syracuse.Craigslist.Org/ Page 2 of 2 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Syracuse.Craigslist.Org/ complete!\n",
      "~240 rows collected.\n",
      "\n",
      "\n",
      "https://twintiers.craigslist.org/ Posts = 8\n",
      "Https://Twintiers.Craigslist.Org/ Pages = 1\n",
      "Https://Twintiers.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Twintiers.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://utica.craigslist.org/ Posts = 66\n",
      "Https://Utica.Craigslist.Org/ Pages = 1\n",
      "Https://Utica.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Utica.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://watertown.craigslist.org/ Posts = 28\n",
      "Https://Watertown.Craigslist.Org/ Pages = 1\n",
      "Https://Watertown.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Watertown.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://asheville.craigslist.org/ Posts = 125\n",
      "Https://Asheville.Craigslist.Org/ Pages = 2\n",
      "Https://Asheville.Craigslist.Org/ Page 1 of 2 pages scraped successfully!\n",
      "Https://Asheville.Craigslist.Org/ Page 2 of 2 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Asheville.Craigslist.Org/ complete!\n",
      "~240 rows collected.\n",
      "\n",
      "\n",
      "https://boone.craigslist.org/ Posts = 21\n",
      "Https://Boone.Craigslist.Org/ Pages = 1\n",
      "Https://Boone.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Boone.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://charlotte.craigslist.org/ Posts = 400\n",
      "Https://Charlotte.Craigslist.Org/ Pages = 4\n",
      "Https://Charlotte.Craigslist.Org/ Page 1 of 4 pages scraped successfully!\n",
      "Https://Charlotte.Craigslist.Org/ Page 2 of 4 pages scraped successfully!\n",
      "Https://Charlotte.Craigslist.Org/ Page 3 of 4 pages scraped successfully!\n",
      "Https://Charlotte.Craigslist.Org/ Page 4 of 4 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Charlotte.Craigslist.Org/ complete!\n",
      "~480 rows collected.\n",
      "\n",
      "\n",
      "https://eastnc.craigslist.org/ Posts = 65\n",
      "Https://Eastnc.Craigslist.Org/ Pages = 1\n",
      "Https://Eastnc.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Eastnc.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://fayetteville.craigslist.org/ Posts = 208\n",
      "Https://Fayetteville.Craigslist.Org/ Pages = 2\n",
      "Https://Fayetteville.Craigslist.Org/ Page 1 of 2 pages scraped successfully!\n",
      "Https://Fayetteville.Craigslist.Org/ Page 2 of 2 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Fayetteville.Craigslist.Org/ complete!\n",
      "~240 rows collected.\n",
      "\n",
      "\n",
      "https://greensboro.craigslist.org/ Posts = 120\n",
      "Https://Greensboro.Craigslist.Org/ Pages = 2\n",
      "Https://Greensboro.Craigslist.Org/ Page 1 of 2 pages scraped successfully!\n",
      "Https://Greensboro.Craigslist.Org/ Page 2 of 2 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Greensboro.Craigslist.Org/ complete!\n",
      "~240 rows collected.\n",
      "\n",
      "\n",
      "https://hickory.craigslist.org/ Posts = 78\n",
      "Https://Hickory.Craigslist.Org/ Pages = 1\n",
      "Https://Hickory.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Hickory.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://onslow.craigslist.org/ Posts = 17\n",
      "Https://Onslow.Craigslist.Org/ Pages = 1\n",
      "Https://Onslow.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Onslow.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://outerbanks.craigslist.org/ Posts = 8\n",
      "Https://Outerbanks.Craigslist.Org/ Pages = 1\n",
      "Https://Outerbanks.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Outerbanks.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://raleigh.craigslist.org/ Posts = 250\n",
      "Https://Raleigh.Craigslist.Org/ Pages = 3\n",
      "Https://Raleigh.Craigslist.Org/ Page 1 of 3 pages scraped successfully!\n",
      "Https://Raleigh.Craigslist.Org/ Page 2 of 3 pages scraped successfully!\n",
      "Https://Raleigh.Craigslist.Org/ Page 3 of 3 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Raleigh.Craigslist.Org/ complete!\n",
      "~360 rows collected.\n",
      "\n",
      "\n",
      "https://wilmington.craigslist.org/ Posts = 113\n",
      "Https://Wilmington.Craigslist.Org/ Pages = 1\n",
      "Https://Wilmington.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Wilmington.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://winstonsalem.craigslist.org/ Posts = 92\n",
      "Https://Winstonsalem.Craigslist.Org/ Pages = 1\n",
      "Https://Winstonsalem.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Winstonsalem.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://bismarck.craigslist.org/ Posts = 3\n",
      "Https://Bismarck.Craigslist.Org/ Pages = 1\n",
      "Https://Bismarck.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Bismarck.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://fargo.craigslist.org/ Posts = 113\n",
      "Https://Fargo.Craigslist.Org/ Pages = 1\n",
      "Https://Fargo.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Fargo.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://grandforks.craigslist.org/ Posts = 18\n",
      "Https://Grandforks.Craigslist.Org/ Pages = 1\n",
      "Https://Grandforks.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Grandforks.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://nd.craigslist.org/ Posts = 7\n",
      "Https://Nd.Craigslist.Org/ Pages = 1\n",
      "Https://Nd.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Nd.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://akroncanton.craigslist.org/ Posts = 187\n",
      "Https://Akroncanton.Craigslist.Org/ Pages = 2\n",
      "Https://Akroncanton.Craigslist.Org/ Page 1 of 2 pages scraped successfully!\n",
      "Https://Akroncanton.Craigslist.Org/ Page 2 of 2 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Akroncanton.Craigslist.Org/ complete!\n",
      "~240 rows collected.\n",
      "\n",
      "\n",
      "https://ashtabula.craigslist.org/ Posts = 6\n",
      "Https://Ashtabula.Craigslist.Org/ Pages = 1\n",
      "Https://Ashtabula.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Ashtabula.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://athensohio.craigslist.org/ Posts = 2\n",
      "Https://Athensohio.Craigslist.Org/ Pages = 1\n",
      "Https://Athensohio.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Athensohio.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://chillicothe.craigslist.org/ Posts = 11\n",
      "Https://Chillicothe.Craigslist.Org/ Pages = 1\n",
      "Https://Chillicothe.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Chillicothe.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://cincinnati.craigslist.org/ Posts = 459\n",
      "Https://Cincinnati.Craigslist.Org/ Pages = 4\n",
      "Https://Cincinnati.Craigslist.Org/ Page 1 of 4 pages scraped successfully!\n",
      "Https://Cincinnati.Craigslist.Org/ Page 2 of 4 pages scraped successfully!\n",
      "Https://Cincinnati.Craigslist.Org/ Page 3 of 4 pages scraped successfully!\n",
      "Https://Cincinnati.Craigslist.Org/ Page 4 of 4 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Cincinnati.Craigslist.Org/ complete!\n",
      "~480 rows collected.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://cleveland.craigslist.org/ Posts = 396\n",
      "Https://Cleveland.Craigslist.Org/ Pages = 4\n",
      "Https://Cleveland.Craigslist.Org/ Page 1 of 4 pages scraped successfully!\n",
      "Https://Cleveland.Craigslist.Org/ Page 2 of 4 pages scraped successfully!\n",
      "Https://Cleveland.Craigslist.Org/ Page 3 of 4 pages scraped successfully!\n",
      "Https://Cleveland.Craigslist.Org/ Page 4 of 4 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Cleveland.Craigslist.Org/ complete!\n",
      "~480 rows collected.\n",
      "\n",
      "\n",
      "https://columbus.craigslist.org/ Posts = 407\n",
      "Https://Columbus.Craigslist.Org/ Pages = 4\n",
      "Https://Columbus.Craigslist.Org/ Page 1 of 4 pages scraped successfully!\n",
      "Https://Columbus.Craigslist.Org/ Page 2 of 4 pages scraped successfully!\n",
      "Https://Columbus.Craigslist.Org/ Page 3 of 4 pages scraped successfully!\n",
      "Https://Columbus.Craigslist.Org/ Page 4 of 4 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Columbus.Craigslist.Org/ complete!\n",
      "~480 rows collected.\n",
      "\n",
      "\n",
      "https://dayton.craigslist.org/ Posts = 91\n",
      "Https://Dayton.Craigslist.Org/ Pages = 1\n",
      "Https://Dayton.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Dayton.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://limaohio.craigslist.org/ Posts = 26\n",
      "Https://Limaohio.Craigslist.Org/ Pages = 1\n",
      "Https://Limaohio.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Limaohio.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://mansfield.craigslist.org/ Posts = 22\n",
      "Https://Mansfield.Craigslist.Org/ Pages = 1\n",
      "Https://Mansfield.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Mansfield.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://sandusky.craigslist.org/ Posts = 16\n",
      "Https://Sandusky.Craigslist.Org/ Pages = 1\n",
      "Https://Sandusky.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Sandusky.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://toledo.craigslist.org/ Posts = 56\n",
      "Https://Toledo.Craigslist.Org/ Pages = 1\n",
      "Https://Toledo.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Toledo.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://tuscarawas.craigslist.org/ Posts = 11\n",
      "Https://Tuscarawas.Craigslist.Org/ Pages = 1\n",
      "Https://Tuscarawas.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Tuscarawas.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://youngstown.craigslist.org/ Posts = 52\n",
      "Https://Youngstown.Craigslist.Org/ Pages = 1\n",
      "Https://Youngstown.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Youngstown.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://zanesville.craigslist.org/ Posts = 15\n",
      "Https://Zanesville.Craigslist.Org/ Pages = 1\n",
      "Https://Zanesville.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Zanesville.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://lawton.craigslist.org/ Posts = 37\n",
      "Https://Lawton.Craigslist.Org/ Pages = 1\n",
      "Https://Lawton.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Lawton.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://enid.craigslist.org/ Posts = 24\n",
      "Https://Enid.Craigslist.Org/ Pages = 1\n",
      "Https://Enid.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Enid.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://oklahomacity.craigslist.org/ Posts = 424\n",
      "Https://Oklahomacity.Craigslist.Org/ Pages = 4\n",
      "Https://Oklahomacity.Craigslist.Org/ Page 1 of 4 pages scraped successfully!\n",
      "Https://Oklahomacity.Craigslist.Org/ Page 2 of 4 pages scraped successfully!\n",
      "Https://Oklahomacity.Craigslist.Org/ Page 3 of 4 pages scraped successfully!\n",
      "Https://Oklahomacity.Craigslist.Org/ Page 4 of 4 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Oklahomacity.Craigslist.Org/ complete!\n",
      "~480 rows collected.\n",
      "\n",
      "\n",
      "https://stillwater.craigslist.org/ Posts = 33\n",
      "Https://Stillwater.Craigslist.Org/ Pages = 1\n",
      "Https://Stillwater.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Stillwater.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://tulsa.craigslist.org/ Posts = 310\n",
      "Https://Tulsa.Craigslist.Org/ Pages = 3\n",
      "Https://Tulsa.Craigslist.Org/ Page 1 of 3 pages scraped successfully!\n",
      "Https://Tulsa.Craigslist.Org/ Page 2 of 3 pages scraped successfully!\n",
      "Https://Tulsa.Craigslist.Org/ Page 3 of 3 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Tulsa.Craigslist.Org/ complete!\n",
      "~360 rows collected.\n",
      "\n",
      "\n",
      "https://bend.craigslist.org/ Posts = 152\n",
      "Https://Bend.Craigslist.Org/ Pages = 2\n",
      "Https://Bend.Craigslist.Org/ Page 1 of 2 pages scraped successfully!\n",
      "Https://Bend.Craigslist.Org/ Page 2 of 2 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Bend.Craigslist.Org/ complete!\n",
      "~240 rows collected.\n",
      "\n",
      "\n",
      "https://corvallis.craigslist.org/ Posts = 47\n",
      "Https://Corvallis.Craigslist.Org/ Pages = 1\n",
      "Https://Corvallis.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Corvallis.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://eastoregon.craigslist.org/ Posts = 10\n",
      "Https://Eastoregon.Craigslist.Org/ Pages = 1\n",
      "Https://Eastoregon.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Eastoregon.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://eugene.craigslist.org/ Posts = 103\n",
      "Https://Eugene.Craigslist.Org/ Pages = 1\n",
      "Https://Eugene.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Eugene.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://klamath.craigslist.org/ Posts = 49\n",
      "Https://Klamath.Craigslist.Org/ Pages = 1\n",
      "Https://Klamath.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Klamath.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://medford.craigslist.org/ Posts = 172\n",
      "Https://Medford.Craigslist.Org/ Pages = 2\n",
      "Https://Medford.Craigslist.Org/ Page 1 of 2 pages scraped successfully!\n",
      "Https://Medford.Craigslist.Org/ Page 2 of 2 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Medford.Craigslist.Org/ complete!\n",
      "~240 rows collected.\n",
      "\n",
      "\n",
      "https://oregoncoast.craigslist.org/ Posts = 34\n",
      "Https://Oregoncoast.Craigslist.Org/ Pages = 1\n",
      "Https://Oregoncoast.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Oregoncoast.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://portland.craigslist.org/ Posts = 1077\n",
      "Https://Portland.Craigslist.Org/ Pages = 9\n",
      "Https://Portland.Craigslist.Org/ Page 1 of 9 pages scraped successfully!\n",
      "Https://Portland.Craigslist.Org/ Page 2 of 9 pages scraped successfully!\n",
      "Https://Portland.Craigslist.Org/ Page 3 of 9 pages scraped successfully!\n",
      "Https://Portland.Craigslist.Org/ Page 4 of 9 pages scraped successfully!\n",
      "Https://Portland.Craigslist.Org/ Page 5 of 9 pages scraped successfully!\n",
      "Https://Portland.Craigslist.Org/ Page 6 of 9 pages scraped successfully!\n",
      "Https://Portland.Craigslist.Org/ Page 7 of 9 pages scraped successfully!\n",
      "Https://Portland.Craigslist.Org/ Page 8 of 9 pages scraped successfully!\n",
      "Https://Portland.Craigslist.Org/ Page 9 of 9 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Portland.Craigslist.Org/ complete!\n",
      "~1080 rows collected.\n",
      "\n",
      "\n",
      "https://roseburg.craigslist.org/ Posts = 66\n",
      "Https://Roseburg.Craigslist.Org/ Pages = 1\n",
      "Https://Roseburg.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Roseburg.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://salem.craigslist.org/ Posts = 209\n",
      "Https://Salem.Craigslist.Org/ Pages = 2\n",
      "Https://Salem.Craigslist.Org/ Page 1 of 2 pages scraped successfully!\n",
      "Https://Salem.Craigslist.Org/ Page 2 of 2 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Salem.Craigslist.Org/ complete!\n",
      "~240 rows collected.\n",
      "\n",
      "\n",
      "https://altoona.craigslist.org/ Posts = 19\n",
      "Https://Altoona.Craigslist.Org/ Pages = 1\n",
      "Https://Altoona.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Altoona.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://chambersburg.craigslist.org/ Posts = 14\n",
      "Https://Chambersburg.Craigslist.Org/ Pages = 1\n",
      "Https://Chambersburg.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Chambersburg.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://erie.craigslist.org/ Posts = 25\n",
      "Https://Erie.Craigslist.Org/ Pages = 1\n",
      "Https://Erie.Craigslist.Org/ Page 1 of 1 pages scraped successfully!\n",
      "\n",
      "\n",
      "Https://Erie.Craigslist.Org/ complete!\n",
      "~120 rows collected.\n",
      "\n",
      "\n",
      "https://harrisburg.craigslist.org/ Posts = 139\n",
      "Https://Harrisburg.Craigslist.Org/ Pages = 2\n"
     ]
    }
   ],
   "source": [
    "craigslist_motorcycle_scraper(city_list[193:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://minneapolis.craigslist.org/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_list[193]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
